{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\data_clean_2\\data_clean\\questions\\US\\test.jsonl\"\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line.strip())\n",
    "            data.append(json_obj)\n",
    "    return data\n",
    "\n",
    "# Read the JSONL file\n",
    "jsonl_data = read_jsonl(file_path)\n",
    "\n",
    "# Print the first few items to verify the content\n",
    "for item in jsonl_data[:5]:  # Print first 5 items\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_object_keys = []\n",
    "for qa_object in jsonl_data:\n",
    "    for qa_object_key, qa_object_value in qa_object.items():\n",
    "        if qa_object_key not in qa_object_keys:\n",
    "            qa_object_keys.append(qa_object_key)\n",
    "\n",
    "print(qa_object_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-based text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% pip install pandas pydantic openai tenacity openpyxl tiktoken langchain langchain-community\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import tiktoken\n",
    "\n",
    "# Constants\n",
    "NUMBER_OF_RETRY = 2\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "SAVE_INTERVAL = 5\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# System prompt to guide the AI\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert in medical education and classification. Your task is to categorize medical questions accurately \"\n",
    "    \"according to their relevant systems, disciplines, specialties, and subspecialties, as well as classify them according \"\n",
    "    \"to Bloom's taxonomy. Ensure your responses are concise, accurate, and align with the descriptions provided.\"\n",
    ")\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY_Nar_Amir_MedQA\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set or invalid.\")\n",
    "\n",
    "# Initialize the OpenAI chat model using LangChain\n",
    "chat = ChatOpenAI(model_name=MODEL_NAME, openai_api_key=openai_api_key)\n",
    "\n",
    "class QuestionData(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    options: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "\n",
    "class BloomTaxonomy(BaseModel):\n",
    "    bloom_taxonomy: str = Field(\n",
    "        description=(\n",
    "            \"Classify the cognitive level required to answer the question according to Bloom's Taxonomy. \"\n",
    "            \"Select one of the following levels based on the cognitive process involved:\\n\"\n",
    "            \n",
    "            \"'Remembering': Focuses on recalling specific medical facts or basic concepts. \"\n",
    "            \"Example: 'What is the mechanism of action of beta-blockers?'\\n\"\n",
    "            \n",
    "            \"'Understanding': Involves explaining medical concepts or interpreting clinical data. \"\n",
    "            \"Example: 'How would you explain the pathophysiology of type 2 diabetes?'\\n\"\n",
    "            \n",
    "            \"'Applying': Requires using medical knowledge in clinical scenarios or solving clinical problems. \"\n",
    "            \"Example: 'What is the appropriate initial treatment for a patient presenting with acute myocardial infarction?'\\n\"\n",
    "            \n",
    "            \"'Analyzing': Involves breaking down clinical cases or understanding relationships between medical concepts. \"\n",
    "            \"Example: 'How would you differentiate between the clinical features of Crohn's disease and ulcerative colitis?'\\n\"\n",
    "            \n",
    "            \"'Evaluating': Focuses on making clinical judgments or assessing the validity of diagnostic or treatment options. \"\n",
    "            \"Example: 'Which of the following criteria best supports the diagnosis of metabolic syndrome in a patient?'\\n\"\n",
    "            \n",
    "            \"'Creating': Involves generating new ideas or designing solutions to complex medical problems. \"\n",
    "            \"Example: 'What innovative treatment strategy would you propose for a patient with refractory hypertension?'\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class QuestionLabels(BaseModel):\n",
    "    meta_info_TopicSystem: str = Field(\n",
    "        description=(\n",
    "            \"The primary system or topic classification of the question within the context of USMLE topics. \"\n",
    "            \"This should identify the broader category of medical knowledge that the question falls under. \"\n",
    "            \"Examples include 'Cardiovascular System', 'Reproductive & Endocrine Systems', 'Gastrointestinal System'.\"\n",
    "        )\n",
    "    )\n",
    "    meta_info_TopicDiscipline: str = Field(\n",
    "        description=(\n",
    "            \"The specific discipline or subject area that this question relates to. This should be a focused category \"\n",
    "            \"that falls under the broader system. For Step 1 questions, examples include 'Pharmacology', 'Genetics', \"\n",
    "            \"'Histology & Cell Biology'. For Step 2 questions, this could relate to 'Diagnosis', 'Investigation', 'Treatment'.\"\n",
    "        )\n",
    "    )\n",
    "    meta_info_Speciality: str = Field(\n",
    "        description=(\n",
    "            \"The major class or field of study to which the question belongs. This should categorize the question \"\n",
    "            \"at a high level, distinguishing between fields such as 'Medicine', 'Dentistry', 'Pharmacology', etc.\"\n",
    "        )\n",
    "    )\n",
    "    meta_info_SubSpeciality: str = Field(\n",
    "        description=(\n",
    "            \"The specific subspecialty within the major class that is relevant to the question. This should be a more \"\n",
    "            \"granular classification such as 'Gastroenterology', 'Orthodontics', 'Surgery', etc.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class LabeledQuestionData(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    options: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "    meta_info_TopicSystem: str\n",
    "    meta_info_TopicDiscipline: str\n",
    "    meta_info_Speciality: str\n",
    "    meta_info_SubSpeciality: str\n",
    "    meta_info_BloomTaxonomy: str\n",
    "    meta_info_TokenLength: Dict[str, int] = Field(\n",
    "        description=\"A dictionary containing the token length for the question and each option.\"\n",
    "    )\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(NUMBER_OF_RETRY))\n",
    "def classify_bloom_taxonomy(data: QuestionData) -> BloomTaxonomy:\n",
    "    \"\"\"\n",
    "    Classify the given question according to Bloom's taxonomy.\n",
    "    \"\"\"\n",
    "    bloom_parser = PydanticOutputParser(pydantic_object=BloomTaxonomy)\n",
    "\n",
    "    bloom_prompt = PromptTemplate(\n",
    "        template=(\n",
    "            f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "            \"Classify the following medical question according to Bloom's taxonomy.\\n{format_instructions}\\n\"\n",
    "            \"Question: {question}\\nAnswer: {answer}\\nOptions: {options}\"\n",
    "        ),\n",
    "        input_variables=[\"question\", \"answer\", \"options\"],\n",
    "        partial_variables={\"format_instructions\": bloom_parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    query = bloom_prompt.format(\n",
    "        question=data.question,\n",
    "        answer=data.answer,\n",
    "        options=\", \".join([f\"{k}: {v}\" for k, v in data.options.items()])\n",
    "    )\n",
    "    \n",
    "    with get_openai_callback() as cb:\n",
    "        response = chat([HumanMessage(content=query)])\n",
    "        logging.info(f\"Cost for Bloom Taxonomy classification: ${cb.total_cost:.6f}\")\n",
    "        return bloom_parser.parse(response.content)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(NUMBER_OF_RETRY))\n",
    "def generate_labels(data: QuestionData) -> QuestionLabels:\n",
    "    \"\"\"\n",
    "    Generate topic and discipline labels for the given question.\n",
    "    \"\"\"\n",
    "    label_parser = PydanticOutputParser(pydantic_object=QuestionLabels)\n",
    "\n",
    "    label_prompt = PromptTemplate(\n",
    "        template=(\n",
    "            f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "            \"Provide the best classification for the following categories for this medical question.\\n\"\n",
    "            \"{format_instructions}\\nQuestion: {question}\\nAnswer: {answer}\\nOptions: {options}\"\n",
    "        ),\n",
    "        input_variables=[\"question\", \"answer\", \"options\"],\n",
    "        partial_variables={\"format_instructions\": label_parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    query = label_prompt.format(\n",
    "        question=data.question,\n",
    "        answer=data.answer,\n",
    "        options=\", \".join([f\"{k}: {v}\" for k, v in data.options.items()])\n",
    "    )\n",
    "\n",
    "    with get_openai_callback() as cb:\n",
    "        response = chat([HumanMessage(content=query)])\n",
    "        logging.info(f\"Cost for generating labels: ${cb.total_cost:.6f}\")\n",
    "        return label_parser.parse(response.content)\n",
    "\n",
    "def count_tokens(data: QuestionData) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count tokens for the question and each option using tiktoken.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(MODEL_NAME)\n",
    "\n",
    "    token_counts = {\n",
    "        \"question_Tokenlength\": len(encoding.encode(data.question))\n",
    "    }\n",
    "    token_counts.update({\n",
    "        f\"option_{key}_Tokenlength\": len(encoding.encode(value))\n",
    "        for key, value in data.options.items()\n",
    "    })\n",
    "\n",
    "    return token_counts\n",
    "\n",
    "def add_labels_classification_and_tokens(data: QuestionData) -> LabeledQuestionData:\n",
    "    \"\"\"\n",
    "    Combine labeling, Bloom taxonomy classification, and token counting for a question.\n",
    "    \"\"\"\n",
    "    labels = generate_labels(data)\n",
    "    bloom_taxonomy = classify_bloom_taxonomy(data)\n",
    "    token_lengths = count_tokens(data)\n",
    "    \n",
    "    return LabeledQuestionData(\n",
    "        **data.dict(),\n",
    "        meta_info_TopicSystem=labels.meta_info_TopicSystem,\n",
    "        meta_info_TopicDiscipline=labels.meta_info_TopicDiscipline,\n",
    "        meta_info_Speciality=labels.meta_info_Speciality,\n",
    "        meta_info_SubSpeciality=labels.meta_info_SubSpeciality,\n",
    "        meta_info_BloomTaxonomy=bloom_taxonomy.bloom_taxonomy,\n",
    "        meta_info_TokenLength=token_lengths\n",
    "    )\n",
    "\n",
    "def read_existing_data(output_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Read existing data from the output file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        return []\n",
    "\n",
    "    with open(output_path, 'r', encoding='utf-8') as file:\n",
    "        return [json.loads(line.strip()) for line in file]\n",
    "\n",
    "def save_labeled_data(labeled_data: List[Dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Save labeled data to the output file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        for item in labeled_data:\n",
    "            json.dump(item, file, ensure_ascii=False)\n",
    "            file.write('\\n')\n",
    "    logging.info(f\"Saved {len(labeled_data)} labeled items to {output_path}\")\n",
    "\n",
    "def process_labeling(input_path: str, output_path: str, N: int, continue_from_existing: bool = True):\n",
    "    \"\"\"\n",
    "    Process and label multiple questions from the input file, skipping previously labeled instances.\n",
    "    Includes original data in case of errors.\n",
    "    \"\"\"\n",
    "    # Load existing data if continuing\n",
    "    labeled_data = read_existing_data(output_path) if continue_from_existing else []\n",
    "\n",
    "    # Create a set of already processed question IDs for faster lookup\n",
    "    processed_ids = set(item['question'] for item in labeled_data)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Read new data and process\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        newly_processed_count = 0\n",
    "        total_processed_count = len(labeled_data)\n",
    "        for line in file:\n",
    "            if newly_processed_count >= N:\n",
    "                break\n",
    "            try:\n",
    "                json_obj = json.loads(line.strip())\n",
    "                question_data = QuestionData(**json_obj)\n",
    "                \n",
    "                # Skip if this question has already been processed\n",
    "                if question_data.question in processed_ids:\n",
    "                    continue\n",
    "\n",
    "                logging.info(f\"Started Labeling of #{total_processed_count + 1}: {question_data}\")\n",
    "                labeled_question_data = add_labels_classification_and_tokens(question_data)\n",
    "                logging.info(f\"Finished Labeling of #{total_processed_count + 1}: {labeled_question_data}\")\n",
    "\n",
    "                labeled_data.append(labeled_question_data.dict())\n",
    "                processed_ids.add(question_data.question)\n",
    "                newly_processed_count += 1\n",
    "                total_processed_count += 1\n",
    "\n",
    "                # Save data every SAVE_INTERVAL runs or on the last run\n",
    "                if newly_processed_count % SAVE_INTERVAL == 0 or newly_processed_count == N:\n",
    "                    save_labeled_data(labeled_data, output_path)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging.error(f\"Error decoding JSON on line {total_processed_count + 1}\")\n",
    "                logging.error(f\"Original data: {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing line {total_processed_count + 1}: {str(e)}\")\n",
    "                logging.error(f\"Original data: {json_obj}\")\n",
    "                \n",
    "                # Include the original data in the labeled_data\n",
    "                error_entry = {\n",
    "                    \"error\": str(e),\n",
    "                    \"original_data\": json_obj\n",
    "                }\n",
    "                labeled_data.append(error_entry)\n",
    "                total_processed_count += 1\n",
    "                \n",
    "                # Save data after each error\n",
    "                save_labeled_data(labeled_data, output_path)\n",
    "\n",
    "    logging.info(f\"Labeling, Bloom taxonomy classification, and token counting completed. \"\n",
    "                 f\"Newly processed {newly_processed_count} items. \"\n",
    "                 f\"Total processed {total_processed_count} items. \"\n",
    "                 f\"Data saved to {output_path}\")\n",
    "    \n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"Process and label medical questions.\")\n",
    "#     parser.add_argument(\"input_path\", help=\"Path to the input JSONL file\")\n",
    "#     parser.add_argument(\"output_path\", help=\"Path to the output JSONL file\")\n",
    "#     parser.add_argument(\"--n\", type=int, default=2, help=\"Number of questions to process\")\n",
    "#     parser.add_argument(\"--continue_from_existing\", action=\"store_true\", help=\"Continue from existing output file\")\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     process_labeling(args.input_path, args.output_path, args.n, args.continue_from_existing)\n",
    "\n",
    "input_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\data_clean_2\\data_clean\\questions\\US\\test.jsonl\"\n",
    "output_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\"\n",
    "n=1\n",
    "continue_from_existing=True\n",
    "process_labeling(input_path, output_path, n, continue_from_existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unify Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Unified Terms for meta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_categories_and_terms(jsonl_file):\n",
    "    categories = defaultdict(set)\n",
    "    \n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            for key, value in record.items():\n",
    "                if key.startswith('meta_info_') and key != 'meta_info_TokenLength':\n",
    "                    category = key.split('_')[-1]\n",
    "                    categories[category].add(value)\n",
    "    \n",
    "    # Convert sets to sorted lists for consistent output\n",
    "    return {k: sorted(v) for k, v in categories.items()}\n",
    "\n",
    "# Usage\n",
    "jsonl_file = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\"  # Replace with your actual file name\n",
    "extracted_categories = extract_categories_and_terms(jsonl_file)\n",
    "\n",
    "print(json.dumps(extracted_categories, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.cache import SQLiteCache\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set up caching\n",
    "from langchain.globals import set_llm_cache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "# Pydantic models (unchanged)\n",
    "class TopicSystemTerm(BaseModel):\n",
    "    term: str = Field(description=\"The unified USMLE system-based term\")\n",
    "    reasoning: str = Field(description=\"Explanation for this unification\")\n",
    "\n",
    "class SpecialityTerm(BaseModel):\n",
    "    term: str = Field(description=\"The unified speciality term\")\n",
    "    category: str = Field(description=\"Category of the speciality (e.g., Medical Practitioner, Dental Student)\")\n",
    "    reasoning: str = Field(description=\"Explanation for this classification\")\n",
    "\n",
    "class SubSpecialityTerm(BaseModel):\n",
    "    term: str = Field(description=\"The unified subspeciality term\")\n",
    "    rotation: str = Field(description=\"The medical rotation this subspeciality is associated with\")\n",
    "    reasoning: str = Field(description=\"Explanation for this unification and rotation assignment\")\n",
    "\n",
    "class TopicDisciplineTerm(BaseModel):\n",
    "    term: str = Field(description=\"The unified topic discipline term\")\n",
    "    reasoning: str = Field(description=\"Explanation for this unification\")\n",
    "\n",
    "class UnifiedTermsTopicSystem(BaseModel):\n",
    "    unified_terms: List[TopicSystemTerm] = Field(description=\"List of unified TopicSystem terms\")\n",
    "\n",
    "class UnifiedTermsSpeciality(BaseModel):\n",
    "    unified_terms: List[SpecialityTerm] = Field(description=\"List of unified Speciality terms\")\n",
    "\n",
    "class UnifiedTermsSubSpeciality(BaseModel):\n",
    "    unified_terms: List[SubSpecialityTerm] = Field(description=\"List of unified SubSpeciality terms\")\n",
    "\n",
    "class UnifiedTermsTopicDiscipline(BaseModel):\n",
    "    unified_terms: List[TopicDisciplineTerm] = Field(description=\"List of unified TopicDiscipline terms\")\n",
    "\n",
    "def extract_categories_and_terms(jsonl_file: str) -> Dict[str, List[str]]:\n",
    "    categories = defaultdict(set)\n",
    "    \n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            for key, value in record.items():\n",
    "                if key.startswith('meta_info_') and key not in ('meta_info_TokenLength', 'meta_info_BloomTaxonomy'):\n",
    "                    category = key.split('_')[-1]\n",
    "                    categories[category].add(value)\n",
    "    \n",
    "    return {k: sorted(v) for k, v in categories.items()}\n",
    "\n",
    "def get_prompt_template(category: str) -> str:\n",
    "    templates = {\n",
    "        \"TopicSystem\": \"\"\"\n",
    "        Given the following list of terms for the category 'TopicSystem', create a unified list based on USMLE system classifications. Provide granular system-based labels that align with USMLE categories. Explain your reasoning for each unification.\n",
    "\n",
    "        Potential USMLE system classifications include:\n",
    "        - General Principles\n",
    "        - Behavioral Health\n",
    "        - Biostatistics & Epidemiology\n",
    "        - Biochemistry\n",
    "        - Cardiovascular System\n",
    "        - Endocrine System\n",
    "        - Gastrointestinal System\n",
    "        - Hematologic System\n",
    "        - Immune System\n",
    "        - Musculoskeletal System & Skin\n",
    "        - Nervous System & Special Senses\n",
    "        - Renal & Urinary System\n",
    "        - Reproductive System\n",
    "        - Respiratory System\n",
    "\n",
    "        Terms: {terms}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        \"Speciality\": \"\"\"\n",
    "        Given the following list of terms for the category 'Speciality', classify each term into one of these categories: Medical Practitioner, Dental Student, Pharmacy Student, or General Biomedical Student. If a term doesn't fit these categories, choose the most appropriate one or create a new category if necessary. Explain your reasoning for each classification.\n",
    "\n",
    "        Potential categories include:\n",
    "        - Medical Practitioner\n",
    "        - Dental Student\n",
    "        - Pharmacy Student\n",
    "        - General Biomedical Student\n",
    "        - Nursing Student\n",
    "        - Allied Health Professional\n",
    "        - Public Health Professional\n",
    "\n",
    "        Terms: {terms}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        \"SubSpeciality\": \"\"\"\n",
    "        Given the following list of terms for the category 'SubSpeciality', create a unified list of granular medical subspecialties. Consider which rotation a medical student would encounter this topic in. Be as specific as possible while maintaining clinical relevance. Explain your reasoning for each unification.\n",
    "\n",
    "        Potential subspecialities and rotations include:\n",
    "        - Internal Medicine (e.g., Cardiology, Gastroenterology, Pulmonology)\n",
    "        - Surgery (e.g., General Surgery, Orthopedics, Neurosurgery)\n",
    "        - Pediatrics\n",
    "        - Obstetrics and Gynecology\n",
    "        - Psychiatry\n",
    "        - Neurology\n",
    "        - Emergency Medicine\n",
    "        - Radiology\n",
    "        - Anesthesiology\n",
    "        - Pathology\n",
    "        - Family Medicine\n",
    "        - Dermatology\n",
    "        - Ophthalmology\n",
    "        - Otolaryngology\n",
    "        - Urology\n",
    "        - Physical Medicine and Rehabilitation\n",
    "\n",
    "        Terms: {terms}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        \"TopicDiscipline\": \"\"\"\n",
    "        Given the following list of terms for the category 'TopicDiscipline', create a unified list where similar terms are consolidated into a single, representative term. Provide your reasoning for each consolidation.\n",
    "\n",
    "        Potential topic disciplines include:\n",
    "        - Anatomy\n",
    "        - Physiology\n",
    "        - Pathology\n",
    "        - Pharmacology\n",
    "        - Microbiology\n",
    "        - Immunology\n",
    "        - Genetics\n",
    "        - Biochemistry\n",
    "        - Epidemiology\n",
    "        - Biostatistics\n",
    "        - Medical Ethics\n",
    "        - Clinical Skills\n",
    "        - Diagnosis\n",
    "        - Treatment\n",
    "        - Prevention\n",
    "\n",
    "        Terms: {terms}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    return templates.get(category, \"\"\"\n",
    "        Given the following list of terms for the category '{category}', create a unified list where similar terms are consolidated into a single, representative term. Provide your reasoning for each consolidation.\n",
    "\n",
    "        Terms: {terms}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\")\n",
    "\n",
    "def get_unified_terms(category: str, terms: List[str]) -> Dict:\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
    "    \n",
    "    if category == \"TopicSystem\":\n",
    "        parser = PydanticOutputParser(pydantic_object=UnifiedTermsTopicSystem)\n",
    "    elif category == \"Speciality\":\n",
    "        parser = PydanticOutputParser(pydantic_object=UnifiedTermsSpeciality)\n",
    "    elif category == \"SubSpeciality\":\n",
    "        parser = PydanticOutputParser(pydantic_object=UnifiedTermsSubSpeciality)\n",
    "    else:\n",
    "        parser = PydanticOutputParser(pydantic_object=UnifiedTermsTopicDiscipline)\n",
    "    \n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            HumanMessagePromptTemplate.from_template(get_prompt_template(category))\n",
    "        ],\n",
    "        input_variables=[\"category\", \"terms\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = chain.run(category=category, terms=\", \".join(terms))\n",
    "            parsed_response = parser.parse(response)\n",
    "            return parsed_response.dict()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Attempt {attempt + 1} for {category}: Error: {str(e)}. Retrying...\")\n",
    "    \n",
    "    logging.error(f\"Failed to get valid output for {category} after {max_attempts} attempts. Returning empty result.\")\n",
    "    return {\"unified_terms\": []}\n",
    "\n",
    "def process_category(category: str, terms: List[str]) -> Dict[str, Dict]:\n",
    "    logging.info(f\"Processing category: {category}\")\n",
    "    return {category: get_unified_terms(category, terms)}\n",
    "\n",
    "def main():\n",
    "    jsonl_file = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\"\n",
    "    categories = extract_categories_and_terms(jsonl_file)\n",
    "\n",
    "    unified_terms = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_category = {executor.submit(process_category, category, terms): category for category, terms in categories.items()}\n",
    "        for future in as_completed(future_to_category):\n",
    "            category = future_to_category[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                unified_terms.update(result)\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"{category} generated an exception: {exc}\")\n",
    "\n",
    "    with open('unified_terms.json', 'w') as f:\n",
    "        json.dump(unified_terms, f, indent=2)\n",
    "\n",
    "    logging.info(\"Unified terms have been saved to unified_terms.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create map_terms (original-label:unified-term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load the unified terms\n",
    "with open(r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\unified_terms.json\", \"r\") as f:\n",
    "    unified_terms = json.load(f)\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "def get_mapping(category: str, term: str) -> str:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Given the following unified terms for the category '{category}':\\n\"\n",
    "        \"{unified_terms}\\n\\n\"\n",
    "        \"What is the most appropriate unified term for '{term}'? \"\n",
    "        \"Respond with only the unified term, nothing else.\"\n",
    "    )\n",
    "    \n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    response = chain.run(category=category, unified_terms=json.dumps(unified_terms[category], indent=2), term=term)\n",
    "    return response.strip()\n",
    "\n",
    "# Create the mapping\n",
    "map_terms = {}\n",
    "for category in [\"TopicSystem\", \"TopicDiscipline\", \"Speciality\", \"SubSpeciality\"]:\n",
    "    map_terms[category] = {}\n",
    "    \n",
    "    # Read the JSONL file to get all unique terms for each category\n",
    "    unique_terms = set()\n",
    "    with open(r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            term = data.get(f\"meta_info_{category}\")\n",
    "            if term:\n",
    "                unique_terms.add(term)\n",
    "    \n",
    "    # Get mapping for each unique term\n",
    "    for term in unique_terms:\n",
    "        map_terms[category][term] = get_mapping(category, term)\n",
    "\n",
    "# Save the mapping\n",
    "with open(\"map_terms.json\", \"w\") as f:\n",
    "    json.dump(map_terms, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change values in jsonl using map_terms#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the JSON file\n",
    "with open(r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\map_terms_revised.json\", \"r\") as f:\n",
    "    map_terms = json.load(f)\n",
    "\n",
    "# Extract unique values for each category\n",
    "unique_terms = {}\n",
    "for category, terms in map_terms.items():\n",
    "    unique_terms[category] = set(terms.values())\n",
    "\n",
    "# Print the unique terms for each category\n",
    "for category, terms in unique_terms.items():\n",
    "    print(f\"\\nUnique terms for {category}:\")\n",
    "    pprint(sorted(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the original JSONL file\n",
    "input_file = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\"\n",
    "output_file = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens_unifiedterms.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\") as in_f, open(output_file, \"w\") as out_f:\n",
    "    for line in in_f:\n",
    "        data = json.loads(line)\n",
    "        for category in [\"TopicSystem\", \"TopicDiscipline\", \"Speciality\", \"SubSpeciality\"]:\n",
    "            key = f\"meta_info_{category}\"\n",
    "            if key in data:\n",
    "                data[key] = map_terms[category].get(data[key], data[key])\n",
    "        json.dump(data, out_f)\n",
    "        out_f.write(\"\\n\")\n",
    "\n",
    "print(\"Processing complete. Updated JSONL file saved as US-test_labeled_with_bloom_and_tokens_updated.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY_Nar_Amir_MedQA\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set or invalid.\")\n",
    "\n",
    "# Initialize the OpenAI chat model using LangChain\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o\", openai_api_key=openai_api_key)\n",
    "\n",
    "class LabeledQuestionData(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    options: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "    meta_info_TopicSystem: str\n",
    "    meta_info_TopicDiscipline: str\n",
    "    meta_info_Speciality: str\n",
    "    meta_info_SubSpeciality: str\n",
    "    meta_info_BloomTaxonomy: str\n",
    "    meta_info_TokenLength: Dict[str, int]\n",
    "\n",
    "class TranslatedLabeledQuestionData(BaseModel):\n",
    "    question: str\n",
    "    question_persian: str\n",
    "    answer: str\n",
    "    answer_persian: str\n",
    "    options: Dict[str, str]\n",
    "    options_persian: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "    meta_info_TopicSystem: str\n",
    "    meta_info_TopicDiscipline: str\n",
    "    meta_info_Speciality: str\n",
    "    meta_info_SubSpeciality: str\n",
    "    meta_info_BloomTaxonomy: str\n",
    "    meta_info_TokenLength: Dict[str, int]\n",
    "    total_tokens: int\n",
    "    total_cost: float\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def translate_to_persian(text: str) -> (str, int, float):\n",
    "    try:\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "            \"You are an English to Persian translator with deep knowledge of biomedical terms.\"\n",
    "        )\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "            \"Translate the following text to Persian: {text}\"\n",
    "        )\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "        messages = chat_prompt.format_messages(text=text)\n",
    "        with get_openai_callback() as cb:\n",
    "            response = chat(messages)\n",
    "            token_usage = cb.total_tokens\n",
    "            cost = cb.total_cost\n",
    "\n",
    "        return response.content.strip(), token_usage, cost\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        raise\n",
    "\n",
    "def process_translation(input_path: str, output_path: str, N: int, continue_translation: bool = False, checkpoint_interval: int = 5):\n",
    "    translated_data = []\n",
    "    cumulative_tokens = 0\n",
    "    cumulative_cost = 0.0\n",
    "    start_index = 0\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # If continuing translation, read existing data and set the start index\n",
    "    if continue_translation and os.path.exists(output_path):\n",
    "        with open(output_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                translated_data.append(json.loads(line.strip()))\n",
    "            start_index = len(translated_data)\n",
    "            if translated_data:\n",
    "                cumulative_tokens = translated_data[-1]['total_tokens']\n",
    "                cumulative_cost = translated_data[-1]['total_cost']\n",
    "        print(f\"Continuing translation from index {start_index}\")\n",
    "    else:\n",
    "        print(\"Starting new translation\")\n",
    "\n",
    "    def save_checkpoint(data, mode='a'):\n",
    "        with open(output_path, mode, encoding='utf-8') as file:\n",
    "            for item in data:\n",
    "                json.dump(item, file, ensure_ascii=False)\n",
    "                file.write('\\n')\n",
    "        print(f\"Checkpoint saved. Total items: {len(translated_data)}\")\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i < start_index:\n",
    "                continue\n",
    "            if i >= start_index + N:\n",
    "                break\n",
    "            json_obj = json.loads(line.strip())\n",
    "            try:\n",
    "                labeled_data = LabeledQuestionData(**json_obj)\n",
    "                print(f\"Started Translation of #{i+1}: {labeled_data}\")\n",
    "\n",
    "                # Translate the question, answer, and options to Persian\n",
    "                translated_question, tokens_q, cost_q = translate_to_persian(labeled_data.question)\n",
    "                cumulative_tokens += tokens_q\n",
    "                cumulative_cost += cost_q\n",
    "\n",
    "                translated_answer, tokens_a, cost_a = translate_to_persian(labeled_data.answer)\n",
    "                cumulative_tokens += tokens_a\n",
    "                cumulative_cost += cost_a\n",
    "\n",
    "                translated_options = {}\n",
    "                for key, value in labeled_data.options.items():\n",
    "                    translated_opt, tokens_opt, cost_opt = translate_to_persian(value)\n",
    "                    translated_options[key] = translated_opt\n",
    "                    cumulative_tokens += tokens_opt\n",
    "                    cumulative_cost += cost_opt\n",
    "\n",
    "                translated_labeled_data = TranslatedLabeledQuestionData(\n",
    "                    question=labeled_data.question,\n",
    "                    question_persian=translated_question,\n",
    "                    answer=labeled_data.answer,\n",
    "                    answer_persian=translated_answer,\n",
    "                    options=labeled_data.options,\n",
    "                    options_persian=translated_options,\n",
    "                    meta_info=labeled_data.meta_info,\n",
    "                    answer_idx=labeled_data.answer_idx,\n",
    "                    meta_info_TopicSystem=labeled_data.meta_info_TopicSystem,\n",
    "                    meta_info_TopicDiscipline=labeled_data.meta_info_TopicDiscipline,\n",
    "                    meta_info_Speciality=labeled_data.meta_info_Speciality,\n",
    "                    meta_info_SubSpeciality=labeled_data.meta_info_SubSpeciality,\n",
    "                    meta_info_BloomTaxonomy=labeled_data.meta_info_BloomTaxonomy,\n",
    "                    meta_info_TokenLength=labeled_data.meta_info_TokenLength,\n",
    "                    total_tokens=cumulative_tokens,\n",
    "                    total_cost=cumulative_cost\n",
    "                )\n",
    "\n",
    "                print(f\"Finished Translation of #{i+1}: {translated_labeled_data}\")\n",
    "                translated_data.append(translated_labeled_data.dict())\n",
    "\n",
    "                # Save checkpoint after every 'checkpoint_interval' translations\n",
    "                if (i + 1 - start_index) % checkpoint_interval == 0:\n",
    "                    save_checkpoint(translated_data[-checkpoint_interval:])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping line due to error: {e}\")\n",
    "\n",
    "    # Save any remaining data\n",
    "    if len(translated_data) % checkpoint_interval != 0:\n",
    "        save_checkpoint(translated_data[-(len(translated_data) % checkpoint_interval):])\n",
    "\n",
    "    print(f\"Translation completed. Translated {len(translated_data) - start_index} new items.\")\n",
    "    print(f\"Total items in output file: {len(translated_data)}\")\n",
    "    print(f\"Total tokens used: {cumulative_tokens}\")\n",
    "    print(f\"Total cost: ${cumulative_cost:.6f}\")\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "labeled_file_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens_unifiedterms.jsonl\"\n",
    "output_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens_unifiedterms-translated.jsonl\"\n",
    "N = 194  # Adjust this to the number of objects you want to translate\n",
    "continue_translation = True  # Set this to True if you want to continue from a previous run\n",
    "checkpoint_interval = 5  # Save after every 5 translations\n",
    "\n",
    "process_translation(labeled_file_path, output_path, N, continue_translation, checkpoint_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fgiure Draft (before revise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File path\n",
    "file_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens_unifiedterms - beforeReview.jsonl\"\n",
    "\n",
    "# Initialize counters\n",
    "counters = {\n",
    "    \"meta_info_TopicSystem\": Counter(),\n",
    "    \"meta_info_TopicDiscipline\": Counter(),\n",
    "    \"meta_info_Speciality\": Counter(),\n",
    "    \"meta_info_SubSpeciality\": Counter(),\n",
    "    \"meta_info\": Counter()\n",
    "}\n",
    "\n",
    "# Process the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        for key in counters.keys():\n",
    "            if key in data:\n",
    "                counters[key][data[key]] += 1\n",
    "\n",
    "# Print the counts\n",
    "for key, counter in counters.items():\n",
    "    print(f\"\\n{key} counts:\")\n",
    "    for value, count in counter.most_common():\n",
    "        print(f\"{value}: {count}\")\n",
    "\n",
    "# Set up a color palette\n",
    "colors = sns.color_palette(\"husl\", 11)  # 11 colors for 10 top items + 'Other'\n",
    "\n",
    "# Create enhanced pie charts for each category\n",
    "for category, counts in counters.items():\n",
    "    # Sort items by value and get top 10\n",
    "    items = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_items = items[:10]\n",
    "    other = sum(dict(items[10:]).values())\n",
    "    \n",
    "    if other > 0:\n",
    "        top_items.append(('Other', other))\n",
    "    \n",
    "    labels, sizes = zip(*top_items)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))  # Increased figure size\n",
    "    \n",
    "    # Create the pie chart\n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%', \n",
    "                                      pctdistance=0.85, wedgeprops=dict(width=0.5),\n",
    "                                      textprops={'fontsize': 14},  # Increased font size\n",
    "                                      colors=colors[:len(top_items)])  # Use only as many colors as needed\n",
    "    \n",
    "    # Create a circle at the center to turn it into a donut chart\n",
    "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    \n",
    "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    ax.axis('equal')  \n",
    "    \n",
    "    # Add a title\n",
    "    plt.title(f\"Distribution of Terms in {category}\", fontsize=20, fontweight='bold')  # Increased title font size\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend(wedges, labels,\n",
    "              title=\"Terms\",\n",
    "              loc=\"center left\",\n",
    "              bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "              fontsize=12)  # Increased legend font size\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Figures/pie_chart_{category}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nEnhanced pie charts have been saved as PNG files in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create the heatmap\n",
    "topic_systems = list(counters['meta_info_TopicSystem'].keys())\n",
    "topic_disciplines = list(counters['meta_info_TopicDiscipline'].keys())\n",
    "\n",
    "heatmap_matrix = np.zeros((len(topic_disciplines), len(topic_systems)))\n",
    "\n",
    "for i, discipline in enumerate(topic_disciplines):\n",
    "    for j, system in enumerate(topic_systems):\n",
    "        heatmap_matrix[i, j] = heatmap_data[system][discipline]\n",
    "\n",
    "# Create a DataFrame for the heatmap\n",
    "df_heatmap = pd.DataFrame(heatmap_matrix, index=topic_disciplines, columns=topic_systems)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(20, 16))  # Increased figure size\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(df_heatmap, annot=True, fmt='g', cmap='RdYlGn', cbar_kws={'label': 'Count'},\n",
    "            annot_kws={\"size\": 12})  # Increased annotation font size\n",
    "\n",
    "plt.title('Heatmap of Topic System vs Topic Discipline', fontsize=28)  # Increased title font size\n",
    "plt.xlabel('Topic System', fontsize=22)  # Increased x-label font size\n",
    "plt.ylabel('Topic Discipline', fontsize=22)  # Increased y-label font size\n",
    "\n",
    "# Rotate the x-axis labels for better readability and increase font size\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)  # Increased x-tick font size\n",
    "plt.yticks(fontsize=14)  # Increased y-tick font size\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/ssystem_discipline_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nHeatmap with increased font sizes has been saved as 'system_discipline_heatmap.png' in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of values in each label\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the JSON file\n",
    "with open(r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\map_terms_revised.json\", \"r\") as f:\n",
    "    map_terms = json.load(f)\n",
    "\n",
    "# Extract unique values for each category\n",
    "unique_terms = {}\n",
    "for category, terms in map_terms.items():\n",
    "    unique_terms[category] = set(terms.values())\n",
    "\n",
    "# Print the unique terms for each category\n",
    "for category, terms in unique_terms.items():\n",
    "    print(f\"\\nUnique terms for {category}:\")\n",
    "    pprint(sorted(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens_unifiedterms-translated.jsonl\"\n",
    "output_folder = \"Raw_Chunks\"\n",
    "summary_file = \"chunk_summary.xlsx\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read and process the input file\n",
    "data = []\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Initialize chunk dictionaries\n",
    "step1_nonclinical = []\n",
    "subspeciality_chunks = defaultdict(list)\n",
    "others = []\n",
    "\n",
    "# Process data\n",
    "for item in data:\n",
    "    if item['meta_info'] == 'step1' and item['meta_info_TopicDiscipline'] != 'Clinical Diagnosis and Management':\n",
    "        step1_nonclinical.append(item)\n",
    "    elif item['meta_info_SubSpeciality'] in [\n",
    "        \"Gastroenterology\", \"Pediatrics\", \"Obstetrics & Gynecology\", \"Endocrinology\", \"Neurology\",\n",
    "        \"Infectious Diseases\", \"Hematology\", \"Cardiology\", \"Pulmonology\", \"Emergency Medicine\",\n",
    "        \"Psychiatry\", \"Nephrology\", \"Rheumatology\", \"Surgery\", \"Internal Medicine\", \"Dermatology\"\n",
    "    ]:\n",
    "        subspeciality_chunks[item['meta_info_SubSpeciality']].append(item)\n",
    "    else:\n",
    "        others.append(item)\n",
    "\n",
    "# Function to save chunk as JSONL\n",
    "def save_chunk(chunk, filename):\n",
    "    with open(os.path.join(output_folder, filename), 'w', encoding='utf-8') as f:\n",
    "        for item in chunk:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# Function to create chunks of 15 or fewer items\n",
    "def create_chunks(data, base_name):\n",
    "    chunks = []\n",
    "    for i in range(0, len(data), 15):\n",
    "        chunk = data[i:i+15]\n",
    "        chunk_name = f\"{base_name}_{len(chunks)+1}\"\n",
    "        save_chunk(chunk, f\"{chunk_name}.jsonl\")\n",
    "        chunks.append((chunk_name, len(chunk), base_name))\n",
    "    return chunks\n",
    "\n",
    "# Process and save chunks\n",
    "summary = []\n",
    "\n",
    "# Step1_nonClinical chunks\n",
    "random.shuffle(step1_nonclinical)\n",
    "summary.extend(create_chunks(step1_nonclinical, \"Step1_nonClinical\"))\n",
    "\n",
    "# Subspeciality chunks\n",
    "for subspeciality, items in subspeciality_chunks.items():\n",
    "    summary.extend(create_chunks(items, subspeciality))\n",
    "\n",
    "# Others chunk\n",
    "summary.extend(create_chunks(others, \"Others\"))\n",
    "\n",
    "# Create summary DataFrame and save to Excel\n",
    "summary_df = pd.DataFrame(summary, columns=['Chunk Name', 'Number of Instances', 'Applied Filter'])\n",
    "summary_df.to_excel(summary_file, index=False)\n",
    "\n",
    "print(f\"Processing complete. Chunks saved in '{output_folder}' folder.\")\n",
    "print(f\"Summary saved as '{summary_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "# Constants\n",
    "NUMBER_OF_RETRY = 2\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "SAVE_INTERVAL = 5\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY_Nar_Amir_MedQA\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set or invalid.\")\n",
    "\n",
    "# Initialize the OpenAI chat model using LangChain\n",
    "chat = ChatOpenAI(model_name=MODEL_NAME, openai_api_key=openai_api_key)\n",
    "\n",
    "class LabeledQuestionData(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    options: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "    meta_info_TopicSystem: str\n",
    "    meta_info_TopicDiscipline: str\n",
    "    meta_info_Speciality: str\n",
    "    meta_info_SubSpeciality: str\n",
    "    meta_info_BloomTaxonomy: str\n",
    "    meta_info_TokenLength: Dict[str, int]\n",
    "\n",
    "class TranslatedLabeledQuestionData(BaseModel):\n",
    "    question: str\n",
    "    question_persian: str\n",
    "    answer: str\n",
    "    answer_persian: str\n",
    "    options: Dict[str, str]\n",
    "    options_persian: Dict[str, str]\n",
    "    meta_info: str\n",
    "    answer_idx: str\n",
    "    meta_info_TopicSystem: str\n",
    "    meta_info_TopicDiscipline: str\n",
    "    meta_info_Speciality: str\n",
    "    meta_info_SubSpeciality: str\n",
    "    meta_info_BloomTaxonomy: str\n",
    "    meta_info_TokenLength: Dict[str, int]\n",
    "    total_tokens: int\n",
    "    total_cost: float\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(NUMBER_OF_RETRY))\n",
    "def translate_to_persian(text: str) -> (str, int, float):\n",
    "    try:\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "            \"You are an English to Persian translator with deep knowledge of biomedical terms.\"\n",
    "        )\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "            \"Translate the following text to Persian: {text}\"\n",
    "        )\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "        messages = chat_prompt.format_messages(text=text)\n",
    "        with get_openai_callback() as cb:\n",
    "            response = chat(messages)\n",
    "            token_usage = cb.total_tokens\n",
    "            cost = cb.total_cost\n",
    "\n",
    "        return response.content.strip(), token_usage, cost\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during translation: {e}\")\n",
    "        raise\n",
    "\n",
    "def read_existing_data(output_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Read existing data from the output file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        return []\n",
    "\n",
    "    with open(output_path, 'r', encoding='utf-8') as file:\n",
    "        return [json.loads(line.strip()) for line in file]\n",
    "\n",
    "def save_translated_data(translated_data: List[Dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Save translated data to the output file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        for item in translated_data:\n",
    "            json.dump(item, file, ensure_ascii=False)\n",
    "            file.write('\\n')\n",
    "    logging.info(f\"Saved {len(translated_data)} translated items to {output_path}\")\n",
    "\n",
    "def process_translation(input_path: str, output_path: str, N: int, continue_from_existing: bool = True):\n",
    "    # Load existing data if continuing\n",
    "    translated_data = read_existing_data(output_path) if continue_from_existing else []\n",
    "\n",
    "    # Create a set of already processed question IDs for faster lookup\n",
    "    processed_ids = set(item['question'] for item in translated_data)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Read new data and process\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        newly_processed_count = 0\n",
    "        total_processed_count = len(translated_data)\n",
    "        cumulative_tokens = sum(item.get('total_tokens', 0) for item in translated_data)\n",
    "        cumulative_cost = sum(item.get('total_cost', 0) for item in translated_data)\n",
    "\n",
    "        for line in file:\n",
    "            if newly_processed_count >= N:\n",
    "                break\n",
    "            try:\n",
    "                json_obj = json.loads(line.strip())\n",
    "                labeled_data = LabeledQuestionData(**json_obj)\n",
    "                \n",
    "                # Skip if this question has already been processed\n",
    "                if labeled_data.question in processed_ids:\n",
    "                    continue\n",
    "\n",
    "                logging.info(f\"Started Translation of #{total_processed_count + 1}: {labeled_data}\")\n",
    "\n",
    "                # Translate the question, answer, and options to Persian\n",
    "                translated_question, tokens_q, cost_q = translate_to_persian(labeled_data.question)\n",
    "                cumulative_tokens += tokens_q\n",
    "                cumulative_cost += cost_q\n",
    "\n",
    "                translated_answer, tokens_a, cost_a = translate_to_persian(labeled_data.answer)\n",
    "                cumulative_tokens += tokens_a\n",
    "                cumulative_cost += cost_a\n",
    "\n",
    "                translated_options = {}\n",
    "                for key, value in labeled_data.options.items():\n",
    "                    translated_opt, tokens_opt, cost_opt = translate_to_persian(value)\n",
    "                    translated_options[key] = translated_opt\n",
    "                    cumulative_tokens += tokens_opt\n",
    "                    cumulative_cost += cost_opt\n",
    "\n",
    "                translated_labeled_data = TranslatedLabeledQuestionData(\n",
    "                    question=labeled_data.question,\n",
    "                    question_persian=translated_question,\n",
    "                    answer=labeled_data.answer,\n",
    "                    answer_persian=translated_answer,\n",
    "                    options=labeled_data.options,\n",
    "                    options_persian=translated_options,\n",
    "                    meta_info=labeled_data.meta_info,\n",
    "                    answer_idx=labeled_data.answer_idx,\n",
    "                    meta_info_TopicSystem=labeled_data.meta_info_TopicSystem,\n",
    "                    meta_info_TopicDiscipline=labeled_data.meta_info_TopicDiscipline,\n",
    "                    meta_info_Speciality=labeled_data.meta_info_Speciality,\n",
    "                    meta_info_SubSpeciality=labeled_data.meta_info_SubSpeciality,\n",
    "                    meta_info_BloomTaxonomy=labeled_data.meta_info_BloomTaxonomy,\n",
    "                    meta_info_TokenLength=labeled_data.meta_info_TokenLength,\n",
    "                    total_tokens=cumulative_tokens,\n",
    "                    total_cost=cumulative_cost\n",
    "                )\n",
    "\n",
    "                logging.info(f\"Finished Translation of #{total_processed_count + 1}: {translated_labeled_data}\")\n",
    "                translated_data.append(translated_labeled_data.dict())\n",
    "                processed_ids.add(labeled_data.question)\n",
    "                newly_processed_count += 1\n",
    "                total_processed_count += 1\n",
    "\n",
    "                # Save data every SAVE_INTERVAL runs or on the last run\n",
    "                if newly_processed_count % SAVE_INTERVAL == 0 or newly_processed_count == N:\n",
    "                    save_translated_data(translated_data, output_path)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging.error(f\"Error decoding JSON on line {total_processed_count + 1}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing line {total_processed_count + 1}: {str(e)}\")\n",
    "                \n",
    "                # Include the original data in the translated_data\n",
    "                error_entry = {\n",
    "                    \"error\": str(e),\n",
    "                    \"original_data\": json_obj\n",
    "                }\n",
    "                translated_data.append(error_entry)\n",
    "                total_processed_count += 1\n",
    "                \n",
    "                # Save data after each error\n",
    "                save_translated_data(translated_data, output_path)\n",
    "\n",
    "    logging.info(f\"Translation completed. Newly processed {newly_processed_count} items. \"\n",
    "                 f\"Total processed {total_processed_count} items. \"\n",
    "                 f\"Total tokens used: {cumulative_tokens}\")\n",
    "    logging.info(f\"Total cost: ${cumulative_cost:.6f}\")\n",
    "    logging.info(f\"Data saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_labeled_with_bloom_and_tokens.jsonl\"\n",
    "output_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\ParsBench-biomedical\\MedQA\\US-test_translated.jsonl\"\n",
    "N = 2  # Adjust this to the number of questions you want to translate\n",
    "continue_from_existing = True\n",
    "\n",
    "process_translation(input_path, output_path, N, continue_from_existing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parsbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
